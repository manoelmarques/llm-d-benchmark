# A scenario to capture running inference-sim on a Kind cluster without requiring GPUs
export LLMDBENCH_DEPLOY_METHODS=modelservice
export LLMDBENCH_VLLM_COMMON_REPLICAS=1
export LLMDBENCH_VLLM_COMMON_ACCELERATOR_NR=0
export LLMDBENCH_VLLM_COMMON_CPU_NR=0
export LLMDBENCH_VLLM_COMMON_CPU_MEM=100Mi
export LLMDBENCH_VLLM_COMMON_SHM_MEM=500Mi
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_TENSOR_PARALLELISM=0
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_TENSOR_PARALLELISM=0
export LLMDBENCH_VLLM_COMMON_MAX_MODEL_LEN=1024
export LLMDBENCH_VLLM_COMMON_AFFINITY=kubernetes.io/os:linux
export LLMDBENCH_CONTROL_WAIT_TIMEOUT=90
export LLMDBENCH_LLMD_IMAGE_NAME="llm-d-inference-sim"
export LLMDBENCH_LLMD_ROUTINGSIDECAR_IMAGE_TAG="v0.2.0@sha256:a623a0752af0a71b7b05ebf95517848b5dbc3d8d235c1897035905632d5b7d80"
export LLMDBENCH_VLLM_STANDALONE_IMAGE_REGISTRY=ghcr.io
export LLMDBENCH_VLLM_STANDALONE_IMAGE_REPO=llm-d
export LLMDBENCH_VLLM_STANDALONE_IMAGE_NAME=llm-d-inference-sim
export LLMDBENCH_VLLM_STANDALONE_IMAGE_TAG=auto
export LLMDBENCH_VLLM_STANDALONE_ARGS="/app/llm-d-inference-sim____--model____/model-cache/models/REPLACE_ENV_LLMDBENCH_DEPLOY_CURRENT_MODEL____--port____REPLACE_ENV_LLMDBENCH_VLLM_COMMON_INFERENCE_PORT____--served-model-name____REPLACE_ENV_LLMDBENCH_DEPLOY_CURRENT_MODEL"
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_MODEL_COMMAND=imageDefault
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_MODEL_COMMAND=imageDefault
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_EXTRA_ARGS="[]"
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_EXTRA_ARGS="[]"
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_CPU_NR=0
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_CPU_NR=0
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_CPU_MEM=100Mi
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_CPU_MEM=100Mi
export LLMDBENCH_VLLM_MODELSERVICE_DECODE_SHM_MEM=500Mi
export LLMDBENCH_VLLM_MODELSERVICE_PREFILL_SHM_MEM=500Mi
export LLMDBENCH_VLLM_MODELSERVICE_URI_PROTOCOL="hf"
export LLMDBENCH_VLLM_COMMON_PVC_ACCESS_MODE="ReadWriteOnce"
export LLMDBENCH_DEPLOY_MODEL_LIST="facebook/opt-125m"
export LLMDBENCH_VLLM_COMMON_PVC_MODEL_CACHE_SIZE=2Gi
export LLMDBENCH_HARNESS_PVC_SIZE=3Gi
export LLMDBENCH_VLLM_COMMON_ACCELERATOR_MEMORY=24  # To pass capacity planner sanity checking
